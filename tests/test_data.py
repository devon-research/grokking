import torch
from grokking.data import generate_modular_addition_dataset


def test_modular_addition_data_generation_with_consistency_checks():
    for P in range(1, 5):
        for use_equals in [True, False]:
            dataset = generate_modular_addition_dataset(P, use_equals)
            assert len(dataset) == P**2
            inputs, outputs = dataset.tensors
            assert inputs.size(0) == P**2
            assert inputs.size(1) == 3 if use_equals else 2
            assert len(inputs.size()) == 2
            assert outputs.size(0) == P**2
            assert len(outputs.size()) == 1
            assert outputs.min() == 0
            assert outputs.max() == P - 1
            assert outputs.unique().size(0) == P
            assert outputs.eq(inputs.sum(dim=1) % P).all()


def test_modular_addition_data_generation_with_alternate_implementation():
    modular_base = 113
    use_equals_symbol = True
    # Construct the inputs and outputs.
    input_x = torch.arange(modular_base).repeat_interleave(modular_base)
    input_y = input_x.view(modular_base, modular_base).transpose(0, 1).flatten()
    inputs = torch.stack([input_x, input_y], dim=-1)
    outputs = inputs.sum(dim=1) % modular_base
    if use_equals_symbol:
        # Add a third token to represent the equals symbol to every input.
        # The equals symbol uses an input ID equal to the modular base.
        equals_symbols = torch.full((inputs.size(0), 1), modular_base)
        inputs = torch.cat([inputs, equals_symbols], dim=1)
    reference_dataset = torch.utils.data.TensorDataset(inputs, outputs)
    # Check against the dataset generated by the library function.
    actual_dataset = generate_modular_addition_dataset(modular_base, use_equals_symbol)
    assert torch.equal(reference_dataset.tensors[0], actual_dataset.tensors[0])
    assert torch.equal(reference_dataset.tensors[1], actual_dataset.tensors[1])
